{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?\n",
    "\n",
    "Ans- R-squared, also known as the coefficient of determination, is a statistical measure used to evaluate the goodness-of-fit of a linear regression model. It represents the proportion of the variance in the dependent variable that can be explained by the independent variables in the model.\n",
    "\n",
    "R-squared is calculated by dividing the sum of squared differences between the predicted values and the actual values of the dependent variable by the total sum of squared differences between the actual values and the mean of the dependent variable. The result ranges from 0 to 1, where 0 indicates that the model does not explain any of the variance in the dependent variable, and 1 indicates that the model perfectly explains all the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "\n",
    "Ans- Adjusted R-squared is a modified version of R-squared that takes into account the number of predictors or independent variables in a linear regression model. It adjusts the R-squared value by penalizing the addition of unnecessary variables.\n",
    "\n",
    "Unlike regular R-squared, which always increases or remains the same as more predictors are added to the model, adjusted R-squared can decrease when irrelevant variables are included. It provides a more conservative measure of model goodness-of-fit by adjusting for the number of predictors and helps prevent overfitting.\n",
    "\n",
    "Adjusted R-squared is calculated by subtracting the proportionate reduction in the residual sum of squares due to adding predictors, adjusted for the number of predictors, from 1. It penalizes complex models with many predictors that may not significantly improve the model's explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. When is it more appropriate to use adjusted R-squared?\n",
    "\n",
    "Ans- Adjusted R-squared is more appropriate to use when comparing and evaluating models with different numbers of predictors. It helps address the issue of overfitting by penalizing the inclusion of unnecessary variables in the model. Adjusted R-squared provides a more conservative measure of model performance and can help identify the most parsimonious and reliable model among a set of competing models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "\n",
    "Ans- calculated, and what do they represent?\n",
    "RMSE (Root Mean Squared Error), MSE (Mean Squared Error), and MAE (Mean Absolute Error) are commonly used metrics in regression analysis to evaluate the accuracy and performance of predictive models.\n",
    "\n",
    "RMSE is calculated by taking the square root of the average of the squared differences between the predicted values and the actual values. It represents the standard deviation of the residuals and provides a measure of how much the predicted values deviate from the actual values.\n",
    "\n",
    "MSE is calculated by averaging the squared differences between the predicted values and the actual values. It represents the average of the squared residuals and provides an overall measure of the model's prediction accuracy.\n",
    "\n",
    "MAE is calculated by averaging the absolute differences between the predicted values and the actual values. It represents the average magnitude of the errors and provides a measure of how close the predicted values are to the actual values on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in regression analysis.\n",
    "\n",
    "Ans- RMSE, MSE, and MAE are straightforward and easy to interpret metrics for evaluating regression models.\n",
    "They provide a quantitative measure of the prediction accuracy and the magnitude of errors.\n",
    "They can be used to compare and select between different models based on their performance.\n",
    "RMSE and MSE give more weight to larger errors, which can be useful in certain scenarios.\n",
    "Disadvantages:\n",
    "\n",
    "RMSE and MSE are sensitive to outliers and larger errors due to the squaring operation, which may not always reflect the true performance of the model.\n",
    "MAE treats all errors equally without considering their magnitude, which may not adequately capture the impact of larger errors.\n",
    "These metrics do not provide any information about the direction of errors (overestimation or underestimation), which may be important in certain applications.\n",
    "They do not consider the underlying distribution of errors and assume a symmetrical distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
