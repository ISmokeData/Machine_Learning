{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Define overfitting and underfitting in machine learning. What are the consequences of each and how can they be mitigated?\n",
    "\n",
    "Ans- Overfitting occurs when our machine learning model tries to cover all the data points or more than the required data points present in the given dataset. Because of this, the model starts caching noise and inaccurate values present in the dataset, and all these factors reduce the efficiency and accuracy of the model. The overfitted model has low bias and high variance.\n",
    "\n",
    "Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data. To avoid the overfitting in the model, the fed of training data can be stopped at an early stage, due to which the model may not learn enough from the training data. As a result, it may fail to find the best fit of the dominant trend in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. How can we reduce overfitting? Explain in brief.\n",
    "\n",
    "Ans- Early stopping:\n",
    "Early stopping pauses the training phase before the machine learning model learns the noise in the data. However, getting the timing right is important; else the model will still not give accurate results.\n",
    "\n",
    "Pruning:\n",
    "You might identify several features or parameters that impact the final prediction when you build a model. Feature selection—or pruning—identifies the most important features within the training set and eliminates irrelevant ones. For example, to predict if an image is an animal or human, you can look at various input parameters like face shape, ear position, body structure, etc. You may prioritize face shape and ignore the shape of the eyes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "\n",
    "Ans-Underfitting: A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data, i.e., it only performs well on training data but performs poorly on testing data\n",
    "\n",
    "1. High bias and low variance \n",
    "2.The size of the training dataset used \n",
    "3.is not enough.\n",
    "4.The model is too simple.\n",
    "5.Training data is not cleaned and also contains noise in it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance and how do they affect model performance?\n",
    "\n",
    "Ans- If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias. In the latter condition, the new entries will not perform well. Well, there is something between both of these conditions, known as Trade-off or Bias Variance Trade-off.\n",
    "\n",
    "This tradeoff in complexity is why there is a tradeoff between bias and variance. An algorithm can’t be more complex and less complex at the same time. For the graph, the perfect tradeoff will be like."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your models is overfitting or underfitting?\n",
    "\n",
    "Ans- The best method to detect overfit models is by testing the machine learning models on more data with with comprehensive representation of possible input data values and types. Typically, part of the training data is used as test data to check for overfitting. A high error rate in the testing data indicates overfitting.\n",
    "\n",
    "underfitting : A model under fits when it is too simple with regards to the data it is trying to model.\n",
    "\n",
    "One way to detect such a situation is to use the bias-variance approach, which can be represented like this:\n",
    "\n",
    "Your model is under fitted when you have a high bias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Compare and contrast bias and variance in machine learning. What are some example of high bias and high variance models and how do they differ in terms of their performance?\n",
    "\n",
    "Ans- In machine learning, bias and variance are two important sources of error that can affect the performance of a model.\n",
    "\n",
    "Bias refers to the degree to which a model's predictions differ from the true values of the target variable. A high bias model is one that is too simple and may underfit the training data. This means that the model may miss important patterns in the data and perform poorly on both the training and testing data.\n",
    "\n",
    "Variance, on the other hand, refers to the degree to which a model's predictions vary for different training sets. A high variance model is one that is too complex and may overfit the training data. This means that the model may fit the noise in the training data and perform well on the training data but poorly on the testing data.\n",
    "\n",
    "Some examples of high bias and high variance models are:\n",
    "\n",
    "High bias model: Linear regression is an example of a model with high bias. It assumes a linear relationship between the features and the target variable and may not capture complex non-linear relationships in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. What is regularization in machine learning and how can it be used to prevent overfitting? Describe some common regularization technique and how they work.\n",
    "\n",
    "Ans- Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting.\n",
    "Ridge Regularization , Lasso Regression "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
